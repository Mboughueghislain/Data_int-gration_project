# Requirements
Install:
* Python
* pip

# Create a virtual environment
python -m venv <name_on_virtual_env>

# Activate virtual environment
source <name_on_virtual_env>/bin/activate

# install requirements
pip install -r requirements.txt

# Base Python Interpreter
The base interpreter should point to the virtual environment
<name_on_virtual_env>/bin//bin



# lancer le serveur ssh
ssh localhost

# Démarrez NameNode et DataNode
start-dfs.sh

# lancer le zookeeper
bin/zookeeper-server-start.sh config/zookeeper.properties

# lancer le serveur kafka
~/Téléchargements/kafka37$ bin/kafka-server-start.sh config/server.properties 
                    ou
bin/kafka-server-start.sh config/server.properties


# lancer le consumer
spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.2 kafka/consumer.py

# lancer le producer
python kafka/producer.py

# lancer le spark Shell 
spark-shell

# Uploader les deux 
hdfs dfs -put /data/in-hospital-mortality-trends-by-diagnosis-type.csv /hospital_data/in-hospital-mortality-trends-by-diagnosis-type.csv
hdfs dfs -put /data/in-hospital-mortality-trends-by-health-category.csv /hospital_data/in-hospital-mortality-trends-by-health-category.csv